# Papers on Understanding and Explaining Neural Networks

This is an on-going attempt to consolidate all interesting efforts in the area of understanding / interpreting / explaining / visualizing neural networks.

---------------------------------------

## 1. GUI tools

* Deep Visualization 

## 2. Feature Visualization / Activation Maximization
* DGN-AM
* PPGN

## 3. Heatmap / Attribution

* Learning how to explain neural networks: PatternNet and PatternAttribution ([pdf](https://arxiv.org/abs/1705.05598))

### Layer-wise Backpropagation
* Beyond saliency: understanding convolutional neural networks from saliency prediction on layer-wise relevance propagation ([pdf](https://arxiv.org/abs/1712.08268))

## 4. Bayesian

* Yang, S. C. H., & Shafto, P. Explainable Artificial Intelligence via Bayesian Teaching. NIPS 2017 ([pdf](http://shaftolab.com/assets/papers/yangShafto_NIPS_2017_machine_teaching.pdf))
